{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Titanic Survival Classifier\n",
    "\n",
    "In this project a dataset containing several pieces of information from titanic passengers will be analyzed in order to try to predict whether or not they survived the Titanic's maiden voyage. For this reason several machine learning algorithms will be constructed and their efficacy will be tested.\n",
    "\n",
    "In addition a Kaggle workflow will be created, since this is a very popular [competition](https://www.kaggle.com/c/titanic) on the [Kaggle website](https://www.kaggle.com/). In a Kaggle competition, the competitor is given a dataset to train and test their machine learning model on. In addition, they are given a second, unlabeled dataset on which to make predictions. The user's models are used to predict the labels on the unlabeled dataset. These labels are then submitted to Kaggle and graded on their accuracy. Each competitor is given the chance to keep submitting more results in order to improve their score and standings on the leaderboard. Often many submissions are made as the models are improved iteratively, so it is a good idea to automate the workflow of training and testing a model and then finalizing a submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv('train.csv')\n",
    "holdout = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    608\n",
       "1    209\n",
       "2     28\n",
       "4     18\n",
       "3     16\n",
       "8      7\n",
       "5      5\n",
       "Name: SibSp, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SibSp.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train dataset features 12 columns containing the information of 891 passengers:\n",
    "\n",
    "* `PassengerId`: Unique identifier for each passenger\n",
    "* `Survived`: 0 if passenger perished when the Titanic sank, 1 if they survived\n",
    "* `Pclass`: passenger's ticket class 1-3\n",
    "* `Name`: passenger name\n",
    "* `Sex`: male or female\n",
    "* `Age`\n",
    "* `SibSp`: Number of siblings and spouses on board\n",
    "* `Parch`: Number of parents and children on board\n",
    "* `Ticket`: ticket identifier. Could possibly contain additional pieces of information\n",
    "* `Fare`: price paid for the ticket\n",
    "* `Embarked`: identifier for the port the passenger got onto the titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The holdout set of the data has different passengers and is missing the `Survived` column, which contains the information of whether the passenger survived or not, because this is the target column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing:\n",
    "\n",
    "These are functions previously created, that will help process the data. They will allow for an automated data processing process, making it possible to easily apply the same preprocessing steps to all of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_missing(df):\n",
    "    \"\"\"Handle various missing values in the data set\n",
    "    Args:\n",
    "        df(pandas.DataFrame): dataset to process\n",
    "    Returns:\n",
    "        pandas.DataFrame: Processed dataset\n",
    "    \"\"\"\n",
    "    df[\"Fare\"] = df[\"Fare\"].fillna(train[\"Fare\"].mean())\n",
    "    df[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")\n",
    "    return df\n",
    "\n",
    "def process_age(df):\n",
    "    \"\"\"Process the Age column into pre-defined 'bins' \n",
    "    Args:\n",
    "        df(pandas.DataFrame): dataset to process\n",
    "    Returns:\n",
    "        pandas.DataFrame: Processed dataset\n",
    "    \"\"\"\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n",
    "    cut_points = [-1,0,5,12,18,35,60,100]\n",
    "    label_names = [\"Missing\",\"Infant\",\"Child\",\"Teenager\",\"Young Adult\",\"Adult\",\"Senior\"]\n",
    "    df[\"Age_categories\"] = pd.cut(df[\"Age\"],cut_points,labels=label_names)\n",
    "    return df\n",
    "\n",
    "def process_fare(df):\n",
    "    \"\"\"Process the Fare column into pre-defined 'bins' \n",
    "    Args:\n",
    "        df(pandas.DataFrame): dataset to process\n",
    "    Returns:\n",
    "        pandas.DataFrame: Processed dataset\n",
    "    \"\"\"\n",
    "    cut_points = [-1,12,50,100,1000]\n",
    "    label_names = [\"0-12\",\"12-50\",\"50-100\",\"100+\"]\n",
    "    df[\"Fare_categories\"] = pd.cut(df[\"Fare\"],cut_points,labels=label_names)\n",
    "    return df\n",
    "\n",
    "def process_cabin(df):\n",
    "    \"\"\"Process the Cabin column into pre-defined 'bins' \n",
    "    Args:\n",
    "        df(pandas.DataFrame): dataset to process\n",
    "    Returns:\n",
    "        pandas.DataFrame: Processed dataset\n",
    "    \"\"\"\n",
    "    df[\"Cabin_type\"] = df[\"Cabin\"].str[0]\n",
    "    df[\"Cabin_type\"] = df[\"Cabin_type\"].fillna(\"Unknown\")\n",
    "    df = df.drop('Cabin',axis=1)\n",
    "    return df\n",
    "\n",
    "def process_titles(df):\n",
    "    \"\"\"Extract and categorize the title from the name column \n",
    "    Args:\n",
    "        df(pandas.DataFrame): dataset to process\n",
    "    Returns:\n",
    "        pandas.DataFrame: Processed dataset\n",
    "    \"\"\"\n",
    "    titles = {\n",
    "        \"Mr\" :         \"Mr\",\n",
    "        \"Mme\":         \"Mrs\",\n",
    "        \"Ms\":          \"Mrs\",\n",
    "        \"Mrs\" :        \"Mrs\",\n",
    "        \"Master\" :     \"Master\",\n",
    "        \"Mlle\":        \"Miss\",\n",
    "        \"Miss\" :       \"Miss\",\n",
    "        \"Capt\":        \"Officer\",\n",
    "        \"Col\":         \"Officer\",\n",
    "        \"Major\":       \"Officer\",\n",
    "        \"Dr\":          \"Officer\",\n",
    "        \"Rev\":         \"Officer\",\n",
    "        \"Jonkheer\":    \"Royalty\",\n",
    "        \"Don\":         \"Royalty\",\n",
    "        \"Sir\" :        \"Royalty\",\n",
    "        \"Countess\":    \"Royalty\",\n",
    "        \"Dona\":        \"Royalty\",\n",
    "        \"Lady\" :       \"Royalty\"\n",
    "    }\n",
    "    extracted_titles = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n",
    "    df[\"Title\"] = extracted_titles.map(titles)\n",
    "    return df\n",
    "\n",
    "def create_dummies(df,column_name):\n",
    "    \"\"\"Create Dummy Columns (One Hot Encoding) from a single Column\n",
    "    Args:\n",
    "        df(pandas.DataFrame): dataset to process\n",
    "    Returns:\n",
    "        pandas.DataFrame: Processed dataset\n",
    "    \"\"\"\n",
    "    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n",
    "    df = pd.concat([df,dummies],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to apply all of the preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_functions(df):\n",
    "    '''Apply all preprocessing steps to a dataset\n",
    "    Args:\n",
    "        df(pandas.DataFrame): dataset to process\n",
    "    Returns:\n",
    "        pandas.DataFrame: processed dataset\n",
    "    '''\n",
    "    df = process_missing(df)\n",
    "    df = process_age(df)\n",
    "    df = process_fare(df)\n",
    "    df = process_titles(df)\n",
    "    df = process_cabin(df)\n",
    "    for column in ['Age_categories', 'Fare_categories', 'Title', 'Cabin_type', 'Sex']:\n",
    "        df = create_dummies(df, column)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the preprocessing can be done by running:\n",
    "\n",
    "`train = apply_functions(train)\n",
    "holdout = apply_functions(holdout)`\n",
    "\n",
    "but first some new features can be engineered. The preprocessing can then be applied to all features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find possible new features, gaining an overview over the data by making histograms for different columns could help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f7e22e32c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.SibSp.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f7e23e3f88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.Parch.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most people on the Titanic were there without their families"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot tables to find possible connections between family size and survival rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f7e2485e48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.pivot_table(values = 'Survived', index = ['Parch']).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "people with no parents or children have a lower survival rate than those with family on board. This does not hold up for people with 5 parents or children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f7e2524208>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.pivot_table(values = 'Survived', index = 'SibSp').plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having siblings and/or a spouse on board also seems to increase the survival probability for 1 or 2 such family members. After this the survival probability decreases drastically.\n",
    "\n",
    "The question now is if these trends carry over when looking at the total size of the family:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam_cols = train[['SibSp', 'Parch', 'Survived']].copy()\n",
    "\n",
    "fam_cols['tots'] = fam_cols['SibSp'] + fam_cols['Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f7e25a1908>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fam_cols.tots.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f7e261f088>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fam_cols.pivot_table(values = 'Survived', index = 'tots').plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a small family on board increases survival probability.\n",
    "Survival probability has a maximum at 3 family members on board.\n",
    "Four or more family members sharply reduce survival probability.\n",
    "Combining the different column might be a good idea to engineer a new feature. The individual columns behave very similarly to their total, which implies that it is probably not important if a family member belonged to the group parent/child or sibling/spouse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering New Feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['famsize'] = train.Parch + train.SibSp\n",
    "holdout['famsize'] = holdout.Parch + holdout.SibSp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve this feature either:\n",
    "\n",
    "* Change it into a binary feature\n",
    "* Make three groups of people\n",
    "\n",
    "The second choice seems to be the better one, because the previous analysis showed that larger families are at a disadvantage for survival when compared to small families. This information would be lost in a feature that only shows if someone was alone or not. \n",
    "\n",
    "On the other hand, the group traveling alone makes up a large majority of the total population. This could be helpful information to some of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_alone(df):\n",
    "    '''Make a feature stating if someone traveled alone or with family\n",
    "    Args:\n",
    "        df(pandas.DataFrame): dataframe to add feature to\n",
    "    Return:\n",
    "        pandas.DataFrame: dataframe with added feature\n",
    "    '''\n",
    "    df.loc[df.famsize == 0, 'alone'] = 1\n",
    "    df.loc[df.famsize != 0, 'alone'] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = make_alone(train)\n",
    "holdout = make_alone(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_fsd(df):\n",
    "    '''Create new feature catigorizing family size:\n",
    "        0   - alone\n",
    "        1-3 - small\n",
    "        > 3 - large\n",
    "    Args:\n",
    "        df(pandas.DataFrame): dataframe to add feature to\n",
    "    Return:\n",
    "        pandas.DataFrame: dataframe with added feature\n",
    "    '''\n",
    "    df.loc[df.famsize == 0, 'famsize_disc'] = 'alone'\n",
    "    df.loc[(df.famsize > 0) & (df.famsize < 4), 'famsize_disc'] = 'small'\n",
    "    df.loc[df.famsize >= 4, 'famsize_disc'] = 'large'\n",
    "    df = create_dummies(df,'famsize_disc')\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = mk_fsd(train)\n",
    "holdout = mk_fsd(holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the new features in place, the preprocessing steps have to be applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original = train.copy()\n",
    "holdout_original = holdout.copy()\n",
    "train = apply_functions(train)\n",
    "holdout = apply_functions(holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is important, that both the `train` and `holdout` set contain the same columns, because otherwise models trained on the `train` dataset would not necessarily be applicable to `holdout`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in holdout.columns:\n",
    "    if (column not in train.columns):\n",
    "        print(str(column) + ' is in holdout, but not in train')\n",
    "for column in train.columns:\n",
    "    if (column not in holdout.columns):\n",
    "        print(str(column) + ' is in train, but not in holdout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column `Survived` is excluded from the holdout so that the contestants in the competition do not have access to the results. The only other discrepancy is the `Cabin_type_T` column. The reason for the discrepancy can be seen when looking at the datasets before applying the functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C    59\n",
      "B    47\n",
      "D    33\n",
      "E    32\n",
      "A    15\n",
      "F    13\n",
      "G     4\n",
      "T     1\n",
      "Name: Cabin, dtype: int64\n",
      "C    35\n",
      "B    18\n",
      "D    13\n",
      "E     9\n",
      "F     8\n",
      "A     7\n",
      "G     1\n",
      "Name: Cabin, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_original.Cabin.str[0].value_counts())\n",
    "print(holdout_original.Cabin.str[0].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The holdout dataset did not contain a single passenger in a cabin with the type T. This seems o be a very rare cabin type, because there is only one in the complete dataset. Maybe these are the captain's quarters. Due to the small variability in the column `Cabin_type_T` caused by there only being one 1 value and the rest all being 0s it would be the best course of action to just drop this column from the train set, since it is unlikely to contribute to the accuracy of any of the machine learning models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns = ['Cabin_type_T'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "Making a function to use the Recursive Feature Elimination with Cross-Validation (RFECV) algorithm in sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(df, estimator = RandomForestClassifier(random_state = 1, n_jobs = -1)):\n",
    "    '''Select best features\n",
    "    Args:\n",
    "        df(pandas.DataFrame): dataset from which to select features\n",
    "        estimator = RandomForest_Classifier(random_state = 1, n_jobs = -1): machine learning model to use\n",
    "    Returns:\n",
    "        list(str): list containing the best performing features.\n",
    "    '''\n",
    "    all_X = df.select_dtypes(exclude = ['object', 'category']).drop(columns = ['Survived', 'PassengerId']).dropna(axis = 1)\n",
    "    all_y = df.Survived\n",
    "\n",
    "    est = estimator\n",
    "\n",
    "    selector = RFECV(est, cv = 10, n_jobs = 4)\n",
    "    selector.fit(all_X, all_y)\n",
    "    columns = all_X.columns[selector.support_]\n",
    "    print(columns)\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'famsize', 'alone',\n",
      "       'famsize_disc_alone', 'famsize_disc_large', 'famsize_disc_small',\n",
      "       'Age_categories_Missing', 'Age_categories_Infant',\n",
      "       'Age_categories_Child', 'Age_categories_Teenager',\n",
      "       'Age_categories_Young Adult', 'Age_categories_Adult',\n",
      "       'Fare_categories_0-12', 'Fare_categories_12-50',\n",
      "       'Fare_categories_50-100', 'Fare_categories_100+', 'Title_Master',\n",
      "       'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Officer', 'Cabin_type_B',\n",
      "       'Cabin_type_C', 'Cabin_type_D', 'Cabin_type_E', 'Cabin_type_Unknown',\n",
      "       'Sex_female', 'Sex_male'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "best_cols = select_features(train, RandomForestClassifier(random_state = 1, n_jobs = -1))\n",
    "all_X = train[best_cols]\n",
    "all_y = train.Survived\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Tuning:\n",
    "\n",
    "Next the `sklearn.model_selection.GridSearchCV` algorithm will be used to determine the best model as well as its settings for the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a list of model dictionaries, to be able to automate the grid search. The list will contain the model names, as well as some important settings for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dics = [{\n",
    "    'name': 'KNeighborsClassifier',\n",
    "    'estimator': KNeighborsClassifier(n_jobs = -1),\n",
    "    'hyperparameters':\n",
    "    {\n",
    "        'n_neighbors': range(1,20, 2),\n",
    "        'weights': ['distance', 'uniform'],\n",
    "        'algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "        'p': [1,2]\n",
    "    }\n",
    "},\n",
    "    {\n",
    "        'name': 'LogisticRegression',\n",
    "        'estimator': LogisticRegression(n_jobs = -1),\n",
    "        'hyperparameters': \n",
    "        {\n",
    "            'solver' : ['newton-cg', 'ldfgs', 'liblinear']    \n",
    "    }\n",
    "    },\n",
    "    {\n",
    "        'name': 'RandomForestClassifier',\n",
    "        'estimator': RandomForestClassifier(random_state = 1, n_jobs = -1),\n",
    "        'hyperparameters':\n",
    "        {\n",
    "            'n_estimators' : [4, 6, 9, 100],\n",
    "            'criterion': ['entropy', 'gini'],\n",
    "            'max_depth': [2, 5, 10],\n",
    "            'max_features': ['log2', 'sqrt'],\n",
    "            'min_samples_leaf': [1, 5, 8],\n",
    "            'min_samples_split': [2, 3, 5]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'MLPClassifier',\n",
    "        'estimator': MLPClassifier(random_state = 1),\n",
    "        'hyperparameters':\n",
    "        {\n",
    "            'hidden_layer_sizes': [(10,), (20,), (30,), (50, 50), (20,20,20,20,20), (512, 256)],\n",
    "            'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "            'max_iter': [100, 1000, 10000],\n",
    "            'learning_rate': ['constant', 'invscaling', 'adaptive']\n",
    "            \n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(df, model_dic):\n",
    "    '''Select the correct model using the grid-search algorithm:\n",
    "    Args:\n",
    "        df(pandas.DataFrame): dataframe to apply the model to\n",
    "        model_dic: dictionary containing the information of each model and the values\n",
    "        to try during the gridsearch\n",
    "    Returns:\n",
    "        best performing parameters, best performing trained model\n",
    "    '''\n",
    "    est = model_dic['estimator']\n",
    "    hp = model_dic['hyperparameters']\n",
    "    grid = GridSearchCV(estimator = est, n_jobs = -1, param_grid = hp, cv = 10)\n",
    "    grid.fit(all_X, all_y)\n",
    "    print(model_dic['name'])\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    return grid.best_params_, grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "{'algorithm': 'kd_tree', 'n_neighbors': 3, 'p': 1, 'weights': 'uniform'}\n",
      "0.7845318352059926\n",
      "LogisticRegression\n",
      "{'solver': 'newton-cg'}\n",
      "0.823832709113608\n",
      "RandomForestClassifier\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.8384019975031209\n",
      "MLPClassifier\n",
      "{'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.8170786516853932\n"
     ]
    }
   ],
   "source": [
    "for model in model_dics:\n",
    "    results = select_model(train, model)\n",
    "    model['best_params'] = results[0]\n",
    "    model['best_est'] = results[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with the highest accuracy is the random forest classifier. The Logistic Regression and multi-layer perceptron are very close in score. Now a function will be created to be able to make submissions to Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(df, modelnr):\n",
    "    '''Make predictions on a dataset using the best settings detected in the grid search\n",
    "    Args:\n",
    "        df (pandas.DataFrame): dataframe to make predictions on\n",
    "        modelnr (int): index of the model in model_dics\n",
    "    Returns:\n",
    "        .CSV file predictions based on a model in the models dictionary, in the right formating\n",
    "        to be used as a Kaggle submission\n",
    "    '''\n",
    "    predictions = model_dics[modelnr]['best_est'].predict(df[best_cols])\n",
    "    pred_df = pd.DataFrame(\n",
    "        {\n",
    "            'PassengerID' : df.PassengerId,\n",
    "            'Survived' : predictions\n",
    "        }\n",
    "    )\n",
    "    pred_df.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model will be used first, since it performed the highest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions(holdout, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerID</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerID  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF:\n",
    "The random forest model achieved an accuracy score of 0.79425 on Kaggle, which is very close to what it achieved when tested on the train model. But because two other models scored very close to the same accuracy as the random forest, they will also be used to make submissions to Kaggle. First off, the linear regression model will be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions(holdout, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR:\n",
    "The linear regression model scored 0.77511, which is slightly worse than that of the random forest. Next, the multi-layer perceptron will be tested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions(holdout, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP:\n",
    "\n",
    "The multi-layer preceptron achieved a score of 0.78468, which is better than the linear regression model and worse than the random forest model. This is what is expected from the accuracy scores the models achieve when applied to the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "In this project four different machine learning models were used to predict whether or not different passengers of the Titanic would survive the trip: a k-nearest neighbors classifier, a linear regression classifier, a random forest classifier and a multi-layer perceptron. The last three of these performed very similarly when applied to the train set at an accuracy score of 81% - 83%. The k-nearest neighbors model performed worse at 78%.The highest scoring model was the random forest.\n",
    "\n",
    "The three models were then used to create submissions for the Kaggle competition based on the dataset. Here they all performed very similarly as when applied on the train set. Again the random forest model performed the best by a slight margin at 79.4% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addendum:\n",
    "\n",
    "## MLP in Tensorflow\n",
    "\n",
    "Here I attempted to make a multi-layer perceptron in Tensorflow from scratch to achieve the same result as the mlp model using sklearn. This was done, so I could understand the way neural networks work from the ground up. Unfortunately as of writing this it is not converging. I may come back to this in the future, as I learn more about neural networks and understand what is going wrong. If I get it to work, I will also improve the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import os\n",
    "os.environ['TF_MIN_GPU_MULTIPROCESSOR_COUNT']='4'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "s = tf.InteractiveSession()\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the selected features from all_X and holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(691, 32) (200, 32)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "tf_X = normalize(all_X[best_cols], axis = 0)\n",
    "tf_X = tf_X.astype(np.float32)\n",
    "tf_X_test = tf_X[-200:]\n",
    "tf_X = tf_X[:-200]\n",
    "print(tf_X.shape, tf_X_test.shape)\n",
    "tf_holdout = normalize(holdout[best_cols], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "turning the labels into a one-hot encoded vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "tf_y = lb.fit_transform(all_y)\n",
    "tf_y = tf_y.astype(np.float32)\n",
    "tf_y_test = tf_y[-200:]\n",
    "tf_y = tf_y[:-200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will at first have the proportions: \n",
    "#features(input) - 512(hidden layer 1) - 256(hidden-layer 2) - 1(Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "num_features = tf_X.shape[1]\n",
    "num_output = 1\n",
    "num_layers_0 = 512\n",
    "num_layers_1 = 256\n",
    "starter_learning_rate = 0.001\n",
    "regularizer_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholders for  Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_X = tf.placeholder('float32', shape = (None, num_features), name = 'input_X')\n",
    "input_y = tf.placeholder('float32', shape = (None, num_classes), name = 'input_y')\n",
    "# for dropout\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the dense layers with a random normal distribution with zero meand and a small vaiance (1/sqrt(number of features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\apist\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "weights_0 = tf.Variable(tf.random_normal([num_features, num_layers_0], stddev = 1/tf.sqrt(float(num_features))))\n",
    "bias_0 = tf.Variable(tf.random_normal([num_layers_0]))\n",
    "\n",
    "weights_1 = tf.Variable(tf.random_normal([num_layers_0, num_layers_1], stddev = 1/tf.sqrt(float(num_layers_0))))\n",
    "bias_1 = tf.Variable(tf.random_normal([num_layers_1]))\n",
    "\n",
    "weights_2 = tf.Variable(tf.random_normal([num_layers_1, num_output], stddev = 1/tf.sqrt(float(num_output))))\n",
    "bias_2 = tf.Variable(tf.random_normal([num_output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beginning the graph calculation:\n",
    "\n",
    "1. multiply the input for each layer with its weights\n",
    "2. add the biases\n",
    "3. activation function (for the hidden layers the relu function will be used, the output layers will use a sigmoid function, to produce a probability score to assign each passenger to either 1(survived) or 0(perished))\n",
    "4. using dropout regularization to reduce overfitting. Dropout randomly selects features in the layers it is used on th train a new model. This decreases model complexity and specialization and in turn overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-65-15b468943daf>:3: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Initializing weights and biases:\n",
    "hidden_output_0 = tf.nn.relu(tf.matmul(input_X, weights_0) + bias_0)\n",
    "hidden_output_0_0 = tf.nn.dropout(hidden_output_0, keep_prob)\n",
    "\n",
    "hidden_output_1 = tf.nn.relu(tf.matmul(hidden_output_0_0, weights_1) + bias_1)\n",
    "hidden_output_1_1 = tf.nn.dropout(hidden_output_1, keep_prob)\n",
    "\n",
    "predicted_y = tf.sigmoid(tf.matmul(hidden_output_1_1, weights_2) + bias_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function and regularization:\n",
    "\n",
    "The loss function used will be softmax cross entropy with logits. Loss functions give the model a value to minimize, which is the goal telling the model it is converging.\n",
    "\n",
    "Additional measure against overfitting, regularisation:\n",
    "Additional term is added to the loss function:\n",
    "    -> reduces the values in weight functions\n",
    "    -> results in simpler models and reduces ovefitting\n",
    "L2 regularization will be used, which punishes large values in the weight matrices quadratically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = predicted_y, labels = input_y)) \\\n",
    "+ regularizer_rate * (tf.reduce_sum(tf.square(bias_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer and Learning rate: \n",
    "Exponential decay will be used to reduce the learning rate by 15% every five epochs.\n",
    "The Adam optimizer will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variable learning rate\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, 0, 5, 0.85, staircase = True)\n",
    "## Adam optimizer for finding the right weights\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list = [weights_0 , weights_1, weights_2,\n",
    "                                                                             bias_0, bias_1, bias_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Metrics definition\n",
    "correct_prediction = tf.equal(tf_y, predicted_y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Network:\n",
    "batch optimization size 128 and train for 14 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0. Train loss: 24.93 Train acc: 0.612,test acc: 0.630\n",
      "Epoch1. Train loss: 23.32 Train acc: 0.612,test acc: 0.630\n",
      "Epoch2. Train loss: 21.83 Train acc: 0.612,test acc: 0.630\n",
      "Epoch3. Train loss: 20.44 Train acc: 0.612,test acc: 0.630\n",
      "Epoch4. Train loss: 19.15 Train acc: 0.612,test acc: 0.630\n",
      "Epoch5. Train loss: 17.94 Train acc: 0.612,test acc: 0.630\n",
      "Epoch6. Train loss: 16.82 Train acc: 0.612,test acc: 0.630\n",
      "Epoch7. Train loss: 15.77 Train acc: 0.612,test acc: 0.630\n",
      "Epoch8. Train loss: 14.78 Train acc: 0.612,test acc: 0.630\n",
      "Epoch9. Train loss: 13.87 Train acc: 0.612,test acc: 0.630\n",
      "Epoch10. Train loss: 13.01 Train acc: 0.612,test acc: 0.630\n",
      "Epoch11. Train loss: 12.20 Train acc: 0.612,test acc: 0.630\n",
      "Epoch12. Train loss: 11.45 Train acc: 0.612,test acc: 0.630\n",
      "Epoch13. Train loss: 10.74 Train acc: 0.612,test acc: 0.630\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "## Training parameters\n",
    "batch_size = 16\n",
    "epochs = 14\n",
    "dropout_prob = 0.6\n",
    "\n",
    "training_accuracy = []\n",
    "training_loss = []\n",
    "testing_accuracy = []\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "for epoch in range(epochs):\n",
    "    arr = np.arange(tf_X.shape[0])\n",
    "    np.random.shuffle(arr)\n",
    "    for index in range(0, tf_X.shape[0], batch_size):\n",
    "        s.run(optimizer, {input_X: \n",
    "                         tf_X[arr[index:index+batch_size]],\n",
    "                         input_y:\n",
    "                         tf_y[arr[index:index+batch_size]],\n",
    "                         keep_prob: dropout_prob})\n",
    "    training_accuracy.append(s.run(accuracy, feed_dict = {input_X: tf_X,\n",
    "                                                             input_y: tf_y,\n",
    "                                                             keep_prob: 1}))\n",
    "    training_loss.append(s.run(loss, {input_X: tf_X,\n",
    "                                         input_y: tf_y,\n",
    "                                         keep_prob: 1}))\n",
    "    testing_accuracy.append(accuracy_score(tf_y_test, s.run(predicted_y, {input_X: tf_X_test,\n",
    "                                                                                    keep_prob:1})))\n",
    "    print('Epoch{0}. Train loss: {1:.2f} Train acc: {2:.3f},test acc: {3:.3f}'.format(epoch, \n",
    "                                                                                            training_loss[epoch],\n",
    "                                                                                           training_accuracy[epoch],\n",
    "                                                                                          testing_accuracy[epoch]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
